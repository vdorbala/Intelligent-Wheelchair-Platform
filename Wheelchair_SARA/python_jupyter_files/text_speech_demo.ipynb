{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "from collections import deque\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "LANG_CODE = 'en-US'  # Language to use\n",
    "\n",
    "GOOGLE_SPEECH_URL = 'https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&pfilter=2&lang=%s&maxresults=6' % (LANG_CODE)\n",
    "\n",
    "FLAC_CONV = 'flac -f'  # We need a WAV to FLAC converter. flac is available\n",
    "                       # on Linux\n",
    "\n",
    "# Microphone stream config.\n",
    "CHUNK = 1024  # CHUNKS of bytes to read each time from mic\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "THRESHOLD = 2500  # The threshold intensity that defines silence\n",
    "                  # and noise signal (an int. lower than THRESHOLD is silence).\n",
    "\n",
    "SILENCE_LIMIT = 1  # Silence limit in seconds. The max ammount of seconds where\n",
    "                   # only silence is recorded. When this time passes the\n",
    "                   # recording finishes and the file is delivered.\n",
    "\n",
    "PREV_AUDIO = 0.5  # Previous audio (in seconds) to prepend. When noise\n",
    "                  # is detected, how much of previously recorded audio is\n",
    "                  # prepended. This helps to prevent chopping the beggining of the phrase.\n",
    "\n",
    "        \n",
    "\n",
    "def audio_int(num_samples=50):\n",
    "    \"\"\" Gets average audio intensity of your mic sound. You can use it to get\n",
    "        average intensities while you're talking and/or silent. The average\n",
    "        is the avg of the 20% largest intensities recorded.\n",
    "    \"\"\"\n",
    "\n",
    "    print (\"Getting intensity values from mic.\")\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    values = [math.sqrt(abs(audioop.avg(stream.read(CHUNK), 4))) \n",
    "              for x in range(num_samples)] \n",
    "    values = sorted(values, reverse=True)\n",
    "    r = sum(values[:int(num_samples * 0.2)]) / int(num_samples * 0.2)\n",
    "    print(\" Finished \")\n",
    "    print(\" Average audio intensity is \", r)\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    return r\n",
    "\n",
    "       \n",
    "        \n",
    "def listen_for_speech(threshold=THRESHOLD, num_phrases=-1):\n",
    "    \"\"\"\n",
    "    Listens to Microphone, extracts phrases from it and sends it to \n",
    "    Google's TTS service and returns response. a \"phrase\" is sound \n",
    "    surrounded by silence (according to threshold). num_phrases controls\n",
    "    how many phrases to process before finishing the listening process \n",
    "    (-1 for infinite). \n",
    "    \"\"\"\n",
    "\n",
    "    #Open stream\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* Listening mic. \")\n",
    "    audio2send = []\n",
    "    cur_data = ''  # current chunk  of audio data\n",
    "    rel = RATE/CHUNK\n",
    "    slid_win = deque(maxlen=int(SILENCE_LIMIT * rel))\n",
    "    #Prepend audio from 0.5 seconds before noise was detected\n",
    "    prev_audio = deque(maxlen=int(PREV_AUDIO * rel)) \n",
    "    started = False\n",
    "    n = num_phrases\n",
    "    response = []\n",
    "\n",
    "    while (num_phrases == -1 or n > 0):\n",
    "        cur_data = stream.read(CHUNK)\n",
    "        slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))\n",
    "        #print slid_win[-1]\n",
    "        if(sum([x > THRESHOLD for x in slid_win]) > 0):\n",
    "            if(not started):\n",
    "                print(\"Starting record of phrase\")\n",
    "                started = True\n",
    "            audio2send.append(cur_data)\n",
    "        elif (started is True):\n",
    "            print(\"Finished\") \n",
    "            # The limit was reached, finish capture and deliver.\n",
    "            filename = save_speech(list(prev_audio) + audio2send, p)\n",
    "            # Send file to Google and get response\n",
    "            r = speech_to_text(filename) \n",
    "            if num_phrases == -1:\n",
    "                print(\"Response\", r)\n",
    "            else:\n",
    "                response.append(r)\n",
    "            # Remove temp file. Comment line to review.\n",
    "            os.remove(filename)\n",
    "            # Reset all\n",
    "            started = False\n",
    "            slid_win = deque(maxlen=int(SILENCE_LIMIT * rel))\n",
    "            prev_audio = deque(maxlen=int(0.5 * rel)) \n",
    "            audio2send = []\n",
    "            n -= 1\n",
    "            print(\"Listening ...\")\n",
    "        else:\n",
    "            print(\"ended\")\n",
    "\n",
    "            \n",
    "\n",
    "def save_speech(data, p):\n",
    "    \"\"\" Saves mic data to temporary WAV file. Returns filename of saved \n",
    "        file \"\"\"\n",
    "\n",
    "    filename = 'output_'+str(int(time.time()))\n",
    "    # writes data to WAV file\n",
    "    data = b''.join(data)\n",
    "    wf = wave.open(filename + '.wav', 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(16000)  # TODO make this value a function parameter?\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "    return filename + '.wav'\n",
    "\n",
    "def speech_to_text(filename):\n",
    "    \n",
    "    recognizer = sr.Recognizer()\n",
    "    speech_file = sr.AudioFile('speech.wav')\n",
    "    with speech_file as source:\n",
    "        audio = r.record(source, duration=10) # 4secs of the audio file\n",
    "    text = r.recognize_google(audio) \n",
    "    return text\n",
    "        \n",
    "\n",
    "if(__name__ == '__main__'):\n",
    "    listen_for_speech()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " good morning sarani\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "text = \" good morning sarani\"\n",
    "print(text)\n",
    "speech  = gTTS(text)\n",
    "speech.save('audio.mp3')\n",
    "os.system('mpg123 audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
